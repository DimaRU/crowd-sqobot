; Initial values for any options omitted in more specific config files.
;
; Please do not edit this file to avoid problems when upgrading.
; Use user-level files like main.conf instead.
;

;------------------------------------------------------------------------
; Database
;------------------------------------------------------------------------

dbDSN             = mysql:host=localhost;dbname=tp_bot
dbUser            = root
dbPassword        =
dbPrefix          = st_
dbEngine          = InnoDB

dbConCharset      = utf8

; Affects DATETIME fields. Empty value equals to 'timeZone' setting or default
; PHP value if 'timeZone' is empty.
; This generally is a TZ identifier ("UTC") or a string like +0:00.
;
dbConTimeZone     =

; All but '' and 0 values enable off-loaded table listing all per-site IDs that
; should not be crawled. Useful for distributed spider to keep all instances in
; sync. If '1' table name is set to 'pages'. Final table value starts with dbPrefix.
;
dbPageIndex       =

; Enables logging of executed queries. strftime() %X substrings can be used
; similar to logFile.
dbLog             =

; Sample setting to write queries to this file.
;dbLog             = out/log.sql

; When dbLog exceeds this size it's cleared. Allows for K/M suffixes (Kilo/Megabyte).
dbLogMax          = 50K


;------------------------------------------------------------------------
; Atomation
;------------------------------------------------------------------------

; If enabled all new rows created within transactions won't go into the database
; but will be stored in out/atoms/SEQNAME.php. The atom task's methods can be used
; to pack, unpack and import those commits on a different machine.
;
atomate           =

; Space-separated values: create (when a new row is inserted), update (when a row
; is updated based on some exact criteria). If empty atomation is disabled.
;atomate           = create update

; The minimum number of atoms a dumped transaction must have. Use with care as if
; an abrupt script termination occurs it might wipe out all atoms that were pending
; for dumping. A value of 1 or below (or empty) saves atoms as soon as they appear.
;
atomsPerFile      = 500


;------------------------------------------------------------------------
; Miscellaneous
;------------------------------------------------------------------------

; For date_default_timezone_set(). Highly recommended to match this and dbConTimeZone.
; See http://www.php.net/manual/en/timezones.php for possible values.
; Empty value uses default PHP timezone (from php.ini or elsewhere).
;
timeZone          = UTC

; Seconds after which if a queue item hasn't been fulfilled it's marked as failed.
; Usually Sqobot will mark failed items even on Fatal Errors but if things really
; went wild it might have no chance - in this case items that have timed out are
; marked as such by another process in the beginning of their queue processing job.
;
queueTimeout      = 60

log               = info warn error fatal
logFile           = out/%Y-%m-%d-%a.log


;------------------------------------------------------------------------
; Remote Server Connections
;------------------------------------------------------------------------

; Msec to wait before doing repetitive remote server requests. A random 10% margin
; is added so that for 200 msec actual delay will be between 200 and 220 msec.
remoteDelay       = 500

; Lists of values to be randomly picked when contacting remote server.
;
; Accept-Language header
dl languages      = ru en-us en-gb en de ja cn-zh pt-br es it
; Accept-Charset header
dl charsets       = windows-1251 utf-8 koi8-u big-5 euc-jp shift-jis iso-8859-1
; Accept header
dl mimes          = text/html application/xhtml+xml application/xml

dlRedirects       = 5
; HTTP/1.0 or 1.1.
dlProtocol        = 1.0
; Seconds. Can be float, e.g. 3.5 for 3500 msec. It also affects the timeout of
; inter-node requests.
dlTimeout         = 30
; If set HTTP error statuses (404, 500, etc.) are ignored and exceptions are not thrown.
dlFetchOnError    = 0

; Enables logging of remote requests - their request and response headers, GET
; query, POST size, response status and length and so on. strftime() %X substrings
; can be used similar to logFile.
;
dlLog             = out/dl.log

; When dlLog exceeds this size it's cleared. Allows for K/M suffixes (Kilo/Megabyte).
; Note that it might be overwritten several times during single queue item processing
; if it does many requests.
;
dlLogMax          = 50K


;------------------------------------------------------------------------
; Class Autoloading
;------------------------------------------------------------------------

; Aliasing class to another class name.
class Sqobot\HLEx = Px\HLEx

; HLEx is a utility class required for web interface.
class Px\HLEx     = $hlex.php

; Sample autoloader mapping, overrides default search paths. Initial '$' refers
; to lib/. If path doesn't end on '.php' it's class -> class name alias (as above).
;class SomeClass   = $some.class.php

; Site name -> Sqissor mappings can be listed here. Class name is global (not relative
; to Sqobot\) and will be autoloaded using regular rules including 'class X=file.php'
; mappings above.
;
; If a site isn't listed here it's converted to 'Sqobot\S' + ucfirst(class name with
; removed dots and a symbol following them converted to upper case).
; Example: site.users -> Sqobot\SSiteUsers.
;
;class site.users  = MyNS\UsersParser


;------------------------------------------------------------------------
; URL Caching
;------------------------------------------------------------------------
;
; These settings allow you to store remote pages locally thus avoiding constant
; requests on the same address(es). Very useful for debugging.
;

; Sample URL mappings. They are evaluated recursively until a non-listen URL is
; found - it's then used to retrieve the data. Useful on local systems to speed
; up sqissor debugging saving remote pages locally. URLs are looked up exactly
; as requested (e.g. in download()).
;
;url http://site.name/list.php = file:///home/roger/sqissor/list-1.html
;url http://site.name/list.php?page=1 = http://site.name/list.php?page=0

; Relative paths start from Sqobot's working directory (usually of cli.php).
;url http://site.name/list.php = user/list-1.html

; Empty value terminates lookup and uses left-side URL as final.
;url http://site.name/list.php =

; Note that even local paths should be URL-encoded as they're converted to file:///.
;url http://site.name/list.php = path/with%20spaces.html

; If URL contains '=' you can escape it by doubling (and escape double '='s by
; tripling and so forth). This syntax is valid in any config option, not just 'url'.
;url http://site.name/req.php?a==b&abc=1 = out/cached-req.html

; This URL is translated from http://site.name/req.php?tripled==query.
;url http://site.name/req.php?tripled===query = out/cached-req.html


;------------------------------------------------------------------------
; URL Enqueuer
;------------------------------------------------------------------------
;
; These settings specify operations for `queue url` task.
; Each setting specifies single set of URLs to be added to queue on each task run.
;
; Format:
;
;   qurl [<user-friendly name>] = <Sqissor name> <URL pattern> [<deltas>]
;
; <user-friendly name> can be passed to `queue url` to queue URLs of settings
; starting with given string (plus space) rather than all defined 'qurl' settings.
;
; <URL pattern> may contain '$' to refer to page number and {...} insets evaluated
; as PHP code within Sqobot namespace and with $p variable set to page number.
;
; URL must be reverse-parseable to determine latest page number. For this most
; recent entry of given URL pattern and Sqissor name is fetched from current queue,
; searched for the first '$' or {...}; this value is then converted to integer with
; (int) even if it results in 0 (for non-numeric match). Queue items not matching this
; will be ignored. If no appropriate item is found queuing starts from <initial> page
; (see below).
;
; <deltas> specify how page number changes with each run. Can be omitted.
; It has this format (without spaces, angular brackets omitted for readability):
;
;   [ [-]initial ] [ (-|+)step ] [ =end[.] ] [ /pool ]
;
; <initial> is the initial value of page counter, possibly negative.
; Defaults to '1'.
;
; If <step> is specified page number changes by this value on each run; it omitted
; <step> is set to '+1'.
;
; <end> sets the end value. Once page number becomes exactly this (not more or less)
; it will be reset to <initial> unless followed by a period - in this case no more
; items are enqueued as long as page number of last queued URL equals to <end>.
;
; If <end> is omitted URLs are enqueued infinitely.This makes sense when using hops.
;
; <pool> sets how many items of this type are present in queue at a time.
; Defaults to '50'.
;

; Sample entry for walking given URL from page 1, looping at 500 (inclusive) with
; step = +1: posts?page=1, posts?page=2, ..., posts?page=500, posts?page=1, ...
;qurl some-name = site.name http://example.com/posts?page=$ 1+1=500

; This setting will enqueue pages 334, 332, 330, etc. until 6 and then stop
; (notice the trailing period). Each URL will be of form .../cat-334-RANDOM.html.
;qurl php-code = org.example https://example.org/cat-{ "$p-".mt_rand() }.html 334-2=6.

; The above sample could also be written as:
;qurl php-code = org.example https://example.org/cat-$-{ mt_rand() }.html 334-2=6.

; And this won't work because {...} goes before '$' and is treated as page number
; which will always be random.
;qurl php-code = org.example https://example.org/cat-{ mt_rand() }-$.html 334-2=6.


;------------------------------------------------------------------------
; Queue hops and cycles
;------------------------------------------------------------------------
;
; These settings let you juggle queued URLs to loop within a desired range of pages.
;
; Format:
;
;   hop <Sqissor names> [<URL regexp>] = <hops>
;
; <Sqissor names> is a comma-separated list of handlers with wildcards this rule
; should be applied to. For example: 'site.name,example.*'. The value of '*' will
; match for any Sqissor.
;
; <URL regexp> captures page number from URL being enqueued. Unless starts with
; tilde (~) uses this symbol as delimiters (and no flags). Remember that '=' must
; be doubled or they separate setting value from its key.
; If omitted is set to '(?<=\D)\d+/?$' (takes last numeric part ignoring trailing
; slash if present).
;
; Page number is taken from named capture 'page' (if present, e.g. '(?P<page>\d+)'),
; index 1 (if set) or 0 (full match), then converted to integer with (int).
;
; <hops> define rules for changing page number in matched item-to-be-enququed.
; It has this format (without spaces, angular brackets omitted for readability):
;
;   operator value [operator value [...]] [-> new]
;
; <operator> is one of the following: >, >=, <, <=, =, <>. If multiple operators
; are given they are checked in AND fashion.
;
; <value> is an integer to check current page number (matched by <URL regexp>)
; against using <operator> on its left.
;
; <new> is the new value to change the page number to in the URL. Can be omitted.
; Once changing happens all hop rules are reevaluated. If a rule comes to be
; evaluated twice rewriting is abandoned and last page number is used.
;
; In <new>, if there's only one '<operator> <value>' pair and <operator> isn't '<>'
; the rule is inverted like this (VAL = <value>, NEXT = <value> + 1):
;
;   - for '>'     <=VAL->NEXT
;   - for '>='    <VAL->VAL
;   - for '<'     >=VAL->1
;   - for '<='    >VAL->0
;   - for '='     <>VAL->VAL
;   - for '<>'    ERROR
;
; This allows for convenient looping rules to contain crawling within a specified
; range of pages. For example, if you want this node to process pages 200-399 then
; '>=200,<400' will do it, as well as its equivalent '<200->200,>=400->1'.
;

; Sample hop that will restrict crawling of site.name within 1..49 pages.
;hop site.name pid==(\d+)$ = <50

; Once page 51, 52, 53 or 54 is enqueued it's replaced with page 55.
;hop example \D(\d+)/?$ = >50<55->55

; Same as above but additionally skips to page 80 when 66th page is queued (note
; that it won't trigger for any other like 65 or 67).
;hop example = >50<55->55, =66->80


;------------------------------------------------------------------------
; Web Interface Access
;------------------------------------------------------------------------

; List of default permissions for anyone accessing this Sqobot instance via web
; interface. Perms starting with 'web' allow for web tasks with this name.
; Command-line user is always granted unrestricted access.
;
user                  = webindex webstatus webnodes

; Set to empty string to disallow web access unless allowed for an authorized
; user by more specific options below.
;user                  =

; If value starts with '=' default permissions ('user' with no name) are not used
; and this user always has exactly listed perms. If value is just '=' the user
; has no perms and is denied web access even if 'user' above allows it by default.
;
;user sqipper          = = webstatus webpatch webpages

; Linking PHP_AUTH_USER with his permissions in web interface.
; User name and permissions are case-sensitive.
;user HttpAuthLogin    = weblog

; Asterisk grants all permissions. Use for yourself.
;user aion            = *

cookiePrefix          = sqb-
; Either a number in seconds or a word (see Squall's expire()).
cookieExpire          = month
cookiePath            =
cookieDomain          =
; If empty string will be autoset if request is served via HTTPS or not.
cookieSecure          =

forceHTTPS            = 0

; By default user denials are rendered as 403 Forbidden. This option can be set to
; arbitrary HTTP code (e.g. 404) to conceal the fact that user lacks permissions.
;
; Since Sqobot's error response differs from your webserver's error page (Apache's,
; nginx', etc.) you might also want to set up ErrorDocument like .../web/?quit=404.
;
webDenyAs             = 403


;------------------------------------------------------------------------
; Web Interface Look
;------------------------------------------------------------------------

; Composition of the default web interface page. Asterisk includes all unlisted
; tasks in alphabetical order. If it's not present only listed tasks are shown.
; Tasks to which the user has no access are hidden. Duplicates are ignored.
;
webIndexOrder         = status tasks files patch nodes *

; Links item captions in the top menu with their URL relative to web interface root.
webMenu Start         = .

webStyle common       = $common.css

webScript jquery      = //ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js
; Sample JS libraries loaded from a CDN.
;webScript underscore  = //cdnjs.cloudflare.com/ajax/libs/underscore.js/1.4.4/underscore-min.js
;webScript u.string    = //cdnjs.cloudflare.com/ajax/libs/underscore.string/2.3.0/underscore.string.min.js
webScript common      = $common.js

;------------------------------------------------------------------------
; Remote Sqobot Nodes
;------------------------------------------------------------------------
;
; Listing distributed nodes. 'alpha' is node name displayed for humans. Value
; contains space-separated components: IP/hostname/URL to node's web interface,
; then optional user and password. Level of permissions granted on that node is
; determined by 'user' option(s) in its config file(s).
;
; Node names must be unique. Host can be of any valid URL format, e.g.
; https://example.com:8081/sqobot. If schema is missing it's set to 'http://'.
;

; Node named 'sqalker' on given IP accessed under 'sqipper' user and with a password.
;node sqalker          = 127.0.0.1 sqipper coeMae4jphing5Ee
